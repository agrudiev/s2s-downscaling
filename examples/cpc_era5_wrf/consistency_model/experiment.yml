# Experiment
experiment_name: debug

# Data from preprocessing
max_len: 5000 # maximum number of images to load
validation_ratio: 0.002 # this will get a set of random images by default

# Network to be used by the CM [diffusers, homemade, udffdb, conditional, heavy_diffusers]
network: heavy_diffusers
main_variables: [precip]
conditional_variables: # [hours, months]

# Network configuration
dropout: 0.3

# Distance [l1, l2, lpips]
distance: l1

# Loss weighting
loss_weight: True # whether or nor to use the lambda schedule

# Optimizer
optimizer: radam

# Hyperparameters
learning_rate: 1e-6
batch_size: 1
min_noise: 0.002
imin: 1 # minimum noise step
max_noise: 80.0
imax: 1280 # maximum noise step
mu0: 0.9 # ema decay rating at the beginning of training
s0: 10 # initial discretization steps
s1: 1280 # target discretization steps
discretization_steps: 1280 # [float, schedule, schedule_improved]
mu: 0.0 # EMA decay rating (can be a "schedule")
epochs: 20 # K
EMA_decay_rate: 0.9999 # EMA decay rating for the online network

# Normalizations
log_transform: True # log-transform the data before training
norm_mean: 0.0
norm_std: 2.0

# Logging and checkpointing
log_each: 1000
checkpoint_each: 1 # checkpoint each #number of epochs
